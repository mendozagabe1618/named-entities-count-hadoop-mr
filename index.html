<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Named Entities Word Count by mendozagabe1618</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Named Entities Word Count</h1>
        <h2>Hadoop MapReduce</h2>
        <a href="https://github.com/mendozagabe1618/named-entities-count-hadoop-mr" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="named-entities-word-count" class="anchor" href="#named-entities-word-count" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Named Entities Word Count</h1>

<p>Distributed for counting the named entities in from a large amount of files and counting them using a MapReduce model.</p>

<h3>
<a id="this-bundle-of-code-does-a-few-things" class="anchor" href="#this-bundle-of-code-does-a-few-things" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>This bundle of code does a few things.</h3>

<ul>
<li>A python script grabs sends a HTTP GET request through the arXiv API. Then we parse the Atom XML response to get the URLs to the PDFs for the returned results. arXiv API mostly only uses PDF. It supports other formats, but for sure will support PDF. However, the implementation allows for any input type. Simply limited by the API.</li>
</ul>

<h3>
<a id="work-flow" class="anchor" href="#work-flow" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Work Flow</h3>

<ol>
<li>A python script, run_me.py, takes 2 command line arguments

<ul>
<li>-k "keywords"      - quotes included</li>
<li>-m maxsize</li>
</ul>
</li>
<li>The script then queries using the input keywords and downloads up to the maxsize of docuements.</li>
<li>While this is going on. The Script silently compiles and packages the jar file.</li>
<li>When ready, the script will scp</li>
<li>A python script, run_me.py, prompts SBT to compile and packages all the Java source code, required binaries, etc. into a jar as well as to launch the test suite</li>
</ol>

<h3>
<a id="how-to-run" class="anchor" href="#how-to-run" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How To Run</h3>

<ul>
<li>I encountered a lot of promblems building my solution into a fat jar. It was SBT that was holding me down.could not figure out how to solve the many duplicate dependencies that I had .</li>
</ul>

<pre><code>./script.py -h
usage: script.py [-h] [-k KEYWORDS] [-m MAXRESULTS] [-s SKIPTO] [-c]

optional arguments:
  -h, --help            show this help message and exit
  -k KEYWORDS, --keywords KEYWORDS
                        keywords to searched for. in quotes if multiple
  -m MAXRESULTS, --maxresults MAXRESULTS
                        number of results to query = for.
  -s SKIPTO, --skipto SKIPTO
                        pack: skip downloading of files. must run atleast once
                        hadoop: skip downloading and packaging.
  -c                    Store a constant value
</code></pre>

<p>-c has priority, meaning that if set, the directory will be cleaning before anything else</p>

<p>-k and -m go hand in hand. search keywords and max results    </p>

<p>defaults are "computer science" and 3, respectively</p>

<p>-s is cool in that if you already downloaded documents with -m and -k you can, and/or packaged a jar through indirect calls to sbt package through the script, you can skip those parts so as to SKIP forward.</p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/mendozagabe1618/named-entities-count-hadoop-mr/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/mendozagabe1618/named-entities-count-hadoop-mr/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/mendozagabe1618/named-entities-count-hadoop-mr"></a> is maintained by <a href="https://github.com/mendozagabe1618">mendozagabe1618</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
